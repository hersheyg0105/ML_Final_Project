{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import mobilenet_rm_filt_pt as mb_pt\n",
    "import copy\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mb_pt.MobileNetv1()\n",
    "# summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_fraction_pruning(model, fraction=0.2):\n",
    "    print(\"In channel fraction pruning function\")\n",
    "    mask_dict={}\n",
    "    #print(model.state_dict().items())\n",
    "    #print()\n",
    "    for name, param in model.state_dict().items():\n",
    "        # print(\"The name is \" + name)\n",
    "        # print(\"The param value is below\")\n",
    "        # print(param)\n",
    "        # print()\n",
    "        if ((name == \"conv1.weight\") or ((\"layers\" in name) and (\"conv2\" in name))):\n",
    "            print(name)\n",
    "            score_list = torch.sum(torch.abs(param),dim=(1,2,3)).to('cpu')\n",
    "            print(\"score list\")\n",
    "            print(score_list)\n",
    "            removed_idx = []\n",
    "            threshold = np.percentile(np.abs(score_list), fraction*100)\n",
    "            print(\"threshold value is \" + str(threshold))\n",
    "            for i,score in enumerate(score_list):\n",
    "                if score < threshold:\n",
    "                    removed_idx.append(i)\n",
    "                param[removed_idx,:,:,:] = 0\n",
    "                mask_dict[name]=torch.where(torch.abs(param) > 0,1,0)\n",
    "    model.mask_dict = mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(model, count_zeros=True):\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    for tensor in model.parameters():\n",
    "        t = np.prod(tensor.shape)\n",
    "        nz = np.sum(tensor.detach().cpu().numpy() != 0.0)\n",
    "\n",
    "        total_params += t\n",
    "        nonzero_params += nz\n",
    "    if not count_zeros:\n",
    "        return int(nonzero_params)\n",
    "    else:\n",
    "        return int(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('mbnv1_pt.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3217226"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "about to fraction prune\n",
      "In channel fraction pruning function\n",
      "conv1.weight\n",
      "score list\n",
      "tensor([4.6996, 4.6470, 4.7955, 4.1902, 4.7855, 5.1085, 4.8225, 5.0183, 4.7123,\n",
      "        5.0384, 4.3877, 4.6423, 4.8195, 4.3119, 4.4850, 4.9664, 5.1392, 4.8768,\n",
      "        4.8272, 4.6533, 4.8690, 4.8585, 5.0395, 4.7349, 5.0591, 4.9254, 4.9032,\n",
      "        4.8871, 4.7736, 4.8523, 4.6170, 5.1377])\n",
      "threshold value is 4.719100141525269\n",
      "layers.0.conv2.weight\n",
      "score list\n",
      "tensor([5.3270, 5.6366, 5.3618, 5.7180, 5.3968, 5.2933, 5.0783, 5.3830, 3.7633,\n",
      "        5.1041, 5.3118, 5.3478, 5.0499, 5.6451, 5.7515, 5.2193, 4.5912, 5.0705,\n",
      "        5.6936, 5.4505, 5.0237, 5.5487, 4.8535, 5.1959, 4.8054, 5.4607, 4.8562,\n",
      "        5.5933, 5.2328, 5.4191, 5.7362, 5.3385, 5.5208, 5.5767, 5.2489, 5.8623,\n",
      "        5.1873, 5.0173, 4.9702, 5.2198, 5.5855, 5.8860, 6.5471, 5.7024, 5.3603,\n",
      "        4.9945, 5.1122, 6.0886, 5.7956, 5.1882, 5.7194, 5.8757, 5.6322, 5.2551,\n",
      "        5.7032, 5.2625, 4.9985, 5.1042, 5.2318, 5.7506, 5.3741, 4.8861, 4.9636,\n",
      "        5.6794])\n",
      "threshold value is 5.1881420612335205\n",
      "layers.1.conv2.weight\n",
      "score list\n",
      "tensor([ 9.7751,  9.8419, 10.2736, 10.2403,  9.9953,  9.8520, 10.5299, 10.6111,\n",
      "        10.8331,  9.2177, 10.0289, 10.2210, 10.1805, 10.9067, 10.5499, 10.2609,\n",
      "        10.2903,  9.8586,  9.3925, 10.1455, 10.1842,  9.6707,  9.9813, 10.9394,\n",
      "        10.3744, 10.2109, 10.1833,  9.9645,  9.4452,  9.9226, 10.4655, 10.2387,\n",
      "        10.0385, 10.3127, 10.4241,  9.5743, 10.2115, 10.2570, 11.2992,  9.9270,\n",
      "         8.9665, 10.7757, 10.2362,  9.5062,  9.8836, 10.3057, 10.5476,  9.5852,\n",
      "        11.1208,  9.7454, 10.3144, 10.0833,  9.8388, 10.8460, 10.5337, 10.4277,\n",
      "         9.1956, 10.8781,  9.8792,  9.8451, 10.7652, 10.3100, 10.1885, 10.1662,\n",
      "         8.6341,  9.3155, 10.0508, 10.2776,  9.4706,  9.6534, 10.6293, 10.4801,\n",
      "        10.0810, 10.2078, 10.4588, 10.5076, 10.1888, 10.5701,  9.8101, 10.2573,\n",
      "         9.6582,  9.4206, 10.1324, 10.5856, 10.2407,  9.5642,  9.7544, 10.1715,\n",
      "        10.3534, 10.1444, 10.1492, 10.8391, 10.0188, 10.3043, 11.2066, 10.1171,\n",
      "         9.5354, 10.1472, 10.0272, 10.1326,  9.3459,  9.5579, 10.8691, 11.2112,\n",
      "         9.9161, 10.1944, 10.2356,  9.0491, 10.9832, 10.7232,  9.9754,  9.9651,\n",
      "        10.6665,  8.8986,  9.2824, 10.8296, 10.1653, 10.2880,  9.3574, 10.2906,\n",
      "         9.7324, 10.5167,  9.8745,  9.8527, 10.5934,  9.3686,  9.6134,  8.9184])\n",
      "threshold value is 9.879614925384521\n",
      "layers.2.conv2.weight\n",
      "score list\n",
      "tensor([20.0898, 19.7982, 18.2745, 19.6192, 18.8566, 18.6159, 20.1542, 19.7777,\n",
      "        19.6621, 19.4491, 20.1911, 20.2281, 20.4548, 19.2893, 18.2954, 19.0980,\n",
      "        19.8378, 19.9587, 17.8906, 17.4736, 19.2848, 18.7836, 19.9249, 19.2641,\n",
      "        19.0042, 19.8823, 19.5371, 20.6544, 19.2427, 18.9857, 18.6287, 18.5626,\n",
      "        19.4469, 19.2300, 19.6085, 19.7021, 18.9746, 18.3094, 19.9432, 19.1025,\n",
      "        19.3080, 19.5281, 18.2321, 19.7124, 20.6973, 18.8132, 19.0341, 18.8240,\n",
      "        18.6535, 19.1775, 18.9660, 19.3495, 21.1272, 19.3043, 18.5289, 19.3299,\n",
      "        17.6423, 19.1363, 18.8601, 19.7481, 18.8875, 19.2686, 19.3330, 18.1848,\n",
      "        19.5019, 20.0311, 18.7538, 19.2527, 18.8003, 19.3097, 18.8835, 19.4952,\n",
      "        18.1053, 18.5602, 19.7061, 18.5948, 19.7913, 19.6279, 17.4398, 18.9395,\n",
      "        19.7565, 18.8568, 19.2497, 17.7136, 19.6393, 19.7384, 18.9319, 20.8785,\n",
      "        18.6816, 19.4695, 18.8824, 20.2336, 20.0504, 18.8371, 19.5111, 18.9259,\n",
      "        18.1659, 20.0183, 19.6880, 19.8937, 18.5042, 19.9592, 19.7164, 18.8912,\n",
      "        19.5189, 18.7373, 19.2615, 20.2863, 19.8237, 17.7486, 19.9710, 19.2999,\n",
      "        19.3786, 19.5677, 19.2472, 18.3309, 20.4135, 19.2564, 18.2345, 19.0107,\n",
      "        18.5008, 19.8307, 19.4225, 19.3289, 19.2405, 20.0219, 18.7536, 20.5996])\n",
      "threshold value is 18.88788585662842\n",
      "layers.3.conv2.weight\n",
      "score list\n",
      "tensor([20.8486, 19.9899, 19.9469, 19.3759, 19.9508, 18.2004, 18.4413, 19.5916,\n",
      "        19.6636, 20.3653, 19.4387, 19.6207, 20.0966, 19.7870, 18.9741, 19.9893,\n",
      "        18.5965, 20.5629, 19.8815, 19.3351, 20.2532, 19.4727, 19.1220, 18.0421,\n",
      "        18.1531, 19.3740, 19.4875, 18.7168, 19.0371, 20.4120, 19.4590, 20.0952,\n",
      "        19.5623, 20.5038, 19.2656, 18.0577, 18.4305, 20.6801, 20.2348, 18.5806,\n",
      "        19.2966, 20.1540, 19.7196, 19.7583, 19.8072, 18.1036, 18.1502, 18.8761,\n",
      "        19.1627, 19.7282, 19.5352, 18.6566, 19.2695, 19.9356, 18.4193, 19.9562,\n",
      "        20.5916, 20.4048, 18.6940, 19.9685, 19.9583, 18.4123, 18.9935, 18.6956,\n",
      "        19.7787, 19.4260, 19.4577, 20.2804, 19.7325, 19.3492, 19.7381, 19.6440,\n",
      "        19.4669, 20.1298, 19.1101, 20.2239, 18.1208, 18.5850, 19.4835, 18.8015,\n",
      "        19.6997, 20.3392, 19.7202, 18.9052, 19.2182, 21.0565, 19.3288, 20.0941,\n",
      "        19.5988, 19.7092, 19.5862, 20.2745, 19.0868, 18.3809, 20.0855, 19.3099,\n",
      "        19.4544, 20.2951, 19.5252, 20.3237, 19.8441, 18.7742, 20.8174, 20.5205,\n",
      "        20.5314, 20.4398, 18.3386, 19.1576, 18.5742, 20.5068, 19.7695, 20.3450,\n",
      "        20.4363, 18.3004, 18.5654, 19.7763, 19.5840, 19.4086, 20.1334, 20.2914,\n",
      "        20.3965, 19.7751, 19.7315, 19.4561, 17.6605, 18.9942, 18.7546, 19.8049,\n",
      "        19.2451, 19.5000, 18.9567, 19.7578, 19.6877, 20.2413, 17.3592, 19.8545,\n",
      "        18.4954, 20.1668, 19.8307, 19.5587, 20.4234, 20.3786, 19.5001, 19.9568,\n",
      "        19.0350, 20.3975, 19.4577, 19.5842, 19.3173, 19.2801, 19.6017, 19.7314,\n",
      "        19.1831, 18.5113, 19.4536, 19.0888, 19.5020, 19.3352, 19.1238, 18.3800,\n",
      "        19.8604, 19.3783, 18.0920, 19.8802, 19.7467, 20.3566, 20.2143, 19.1998,\n",
      "        19.9422, 19.7923, 18.4511, 18.7343, 17.7041, 18.8724, 19.7267, 19.7598,\n",
      "        18.9145, 20.1365, 19.4173, 19.6203, 19.6975, 19.4169, 20.3292, 19.5573,\n",
      "        19.4451, 19.1286, 18.6968, 19.1954, 20.6461, 17.9278, 19.1358, 20.5139,\n",
      "        19.9729, 18.6063, 19.3140, 20.7857, 18.5624, 19.0471, 19.8774, 18.4142,\n",
      "        19.7300, 19.7746, 19.3681, 19.7889, 19.1103, 18.0764, 19.0171, 19.7898,\n",
      "        19.7683, 18.9186, 19.8993, 19.1561, 18.9622, 19.8377, 21.0820, 18.6916,\n",
      "        19.9572, 19.2716, 19.9245, 20.5555, 18.4149, 19.9741, 19.3407, 19.9729,\n",
      "        19.2583, 19.7051, 20.2772, 19.4495, 21.1342, 19.6977, 19.5669, 20.1509,\n",
      "        19.6308, 19.3189, 18.7273, 19.6620, 19.4981, 19.6304, 18.3907, 18.8806,\n",
      "        19.8665, 20.4853, 19.8182, 19.6765, 18.9016, 19.0880, 19.7068, 19.8718,\n",
      "        19.7367, 19.8541, 19.9773, 19.8146, 19.6579, 18.8309, 20.0401, 19.1828])\n",
      "threshold value is 19.19758701324463\n",
      "layers.4.conv2.weight\n",
      "score list\n",
      "tensor([37.5480, 37.3620, 39.7843, 38.7936, 37.3257, 40.1662, 38.9631, 38.1656,\n",
      "        38.9352, 39.6094, 39.6444, 38.3766, 38.7740, 39.6463, 37.2695, 38.8293,\n",
      "        37.8727, 40.1658, 38.9422, 38.9736, 36.8623, 37.5211, 38.2985, 38.4274,\n",
      "        38.9803, 38.7553, 38.6660, 38.6214, 37.5428, 38.4187, 38.5753, 38.4141,\n",
      "        37.8840, 38.9426, 38.9355, 37.1552, 38.0685, 37.5646, 39.7664, 38.4502,\n",
      "        37.6988, 38.1345, 38.4348, 39.5346, 37.5378, 37.8571, 39.4474, 38.6669,\n",
      "        39.1932, 39.1261, 36.8791, 38.1126, 37.7428, 38.7248, 39.0986, 38.7433,\n",
      "        39.0962, 39.0322, 37.6792, 37.7512, 36.8699, 37.3388, 40.7063, 39.1168,\n",
      "        38.3660, 37.9472, 38.8114, 36.0546, 38.5307, 40.0544, 37.4762, 38.1194,\n",
      "        38.3384, 37.9364, 39.1771, 40.0068, 37.6120, 39.7134, 38.8026, 39.4376,\n",
      "        39.4877, 40.3704, 37.8561, 37.5278, 39.6118, 39.6908, 38.9256, 38.7446,\n",
      "        38.2933, 37.9735, 37.7432, 38.2758, 39.9279, 37.7354, 39.6991, 38.6397,\n",
      "        37.6394, 37.4248, 38.7382, 38.1362, 38.2620, 39.5246, 38.3404, 37.7522,\n",
      "        37.9393, 38.6645, 38.0085, 38.7305, 37.6584, 37.7050, 40.2568, 37.4516,\n",
      "        37.5529, 38.1011, 37.8071, 38.5452, 38.0268, 37.2596, 37.9074, 39.8327,\n",
      "        37.2177, 37.9280, 38.5349, 36.8408, 38.8321, 38.9387, 37.1425, 39.3550,\n",
      "        37.7997, 38.6903, 38.1506, 38.0767, 37.3455, 37.0336, 39.5060, 38.5049,\n",
      "        39.3504, 38.1901, 38.6847, 40.2225, 38.6073, 37.6105, 39.1293, 38.5370,\n",
      "        38.6091, 39.7159, 38.7263, 37.0589, 38.3622, 39.0419, 39.7311, 37.5286,\n",
      "        40.2560, 38.8025, 38.0328, 36.4070, 38.6429, 37.8903, 37.6542, 38.9418,\n",
      "        39.8228, 37.5296, 38.9445, 39.2514, 36.9468, 37.1818, 38.0801, 38.8998,\n",
      "        37.8768, 36.7574, 38.0586, 39.7167, 38.5921, 38.4266, 38.1570, 38.7379,\n",
      "        38.1543, 39.3237, 38.7805, 39.1372, 37.8457, 37.9179, 38.9622, 37.5066,\n",
      "        39.8065, 39.0911, 38.0368, 39.4561, 37.6921, 36.8764, 38.6243, 36.9400,\n",
      "        37.3859, 38.2534, 40.0348, 39.5132, 38.6681, 38.7489, 38.9552, 38.5442,\n",
      "        38.6445, 37.8648, 37.6034, 38.2144, 38.1278, 38.5500, 39.1174, 37.8623,\n",
      "        40.0367, 37.1541, 38.4269, 38.0351, 38.6919, 37.5973, 36.9648, 38.0060,\n",
      "        37.6787, 38.3929, 37.7182, 37.9817, 38.9440, 37.6858, 40.0149, 38.4438,\n",
      "        39.0460, 39.8687, 37.6640, 39.9814, 39.4542, 36.7981, 38.5346, 39.1725,\n",
      "        39.9430, 37.8511, 38.4671, 38.6935, 37.6746, 39.1618, 39.1661, 37.5924,\n",
      "        38.1619, 37.9788, 39.6527, 38.5915, 39.7510, 38.4416, 39.3776, 39.2187,\n",
      "        39.4515, 38.6598, 38.5959, 38.7568, 38.6989, 39.4812, 38.6174, 38.8938])\n",
      "threshold value is 37.93785285949707\n",
      "layers.5.conv2.weight\n",
      "score list\n",
      "tensor([37.8169, 38.6800, 37.0701, 38.0506, 39.2507, 38.5705, 38.0554, 37.4007,\n",
      "        41.0566, 38.2594, 39.5789, 39.6390, 38.9021, 39.0595, 39.6913, 38.1906,\n",
      "        39.1830, 38.3768, 38.4566, 38.6720, 39.6125, 39.2657, 38.6562, 39.0553,\n",
      "        38.6956, 38.6077, 39.4005, 39.0458, 39.2000, 38.7306, 39.7992, 39.1001,\n",
      "        37.9969, 39.5616, 38.4262, 40.1950, 37.6368, 38.4833, 39.6531, 38.6310,\n",
      "        38.5860, 39.0541, 37.2085, 38.6834, 38.2707, 40.5923, 38.1505, 38.4533,\n",
      "        38.7759, 39.4837, 38.9861, 38.8386, 39.5064, 38.6768, 40.0686, 37.3222,\n",
      "        38.0939, 39.2902, 38.7199, 40.0487, 38.9455, 38.5229, 38.7320, 38.0348,\n",
      "        39.0087, 38.7800, 39.8364, 38.9677, 39.2069, 39.3938, 38.8553, 39.0016,\n",
      "        38.4187, 39.2042, 38.4915, 40.5915, 38.8149, 40.2803, 37.5549, 37.1372,\n",
      "        37.7342, 40.0241, 39.0023, 37.8000, 39.2265, 39.2641, 38.1276, 39.1682,\n",
      "        39.1708, 39.0754, 38.7810, 40.3144, 37.9192, 38.7356, 40.4541, 38.5677,\n",
      "        37.8919, 37.9775, 39.4215, 38.7691, 38.4007, 39.2626, 37.6869, 37.5946,\n",
      "        38.7236, 39.5244, 40.0475, 40.1641, 39.1754, 39.2229, 38.2208, 37.7277,\n",
      "        39.3659, 38.3242, 39.3410, 37.2837, 39.0295, 40.2655, 39.8074, 37.6095,\n",
      "        38.6372, 39.1631, 40.4465, 39.3435, 39.0990, 38.9357, 38.6076, 40.0025,\n",
      "        39.9411, 38.4558, 36.9814, 39.1306, 39.8404, 39.6080, 39.5842, 39.8213,\n",
      "        38.1158, 39.1645, 39.2336, 38.5905, 38.4300, 40.0932, 38.9446, 38.3460,\n",
      "        39.9496, 39.0977, 38.1036, 39.9551, 39.5085, 40.0461, 39.6668, 38.2415,\n",
      "        38.0496, 38.0699, 38.8774, 39.0545, 39.5194, 38.8732, 39.0829, 38.5324,\n",
      "        38.0164, 38.8042, 37.9881, 40.0743, 37.0651, 39.8418, 40.4737, 38.0098,\n",
      "        38.8490, 39.2199, 38.5055, 39.6782, 38.8199, 38.6330, 38.9821, 37.9267,\n",
      "        37.6511, 39.6199, 39.0026, 39.2871, 39.8418, 37.1342, 39.4775, 39.5761,\n",
      "        39.8745, 38.4995, 39.2476, 39.1512, 40.6011, 38.9882, 39.7933, 40.2445,\n",
      "        38.8402, 39.2096, 38.6105, 39.9246, 38.3029, 39.2809, 38.4220, 38.5998,\n",
      "        38.4689, 38.4151, 38.7697, 39.0715, 39.4838, 38.2939, 38.9386, 39.4884,\n",
      "        39.1032, 38.1873, 37.2106, 40.0587, 38.2524, 39.1035, 40.6230, 37.8455,\n",
      "        38.0554, 38.8642, 40.6730, 37.7663, 38.8638, 38.7826, 38.6298, 36.8977,\n",
      "        38.6807, 37.8086, 38.5916, 39.1025, 37.3542, 39.1805, 40.0966, 39.0292,\n",
      "        39.9770, 39.7819, 39.5671, 39.0069, 38.2856, 38.8116, 39.0389, 38.7324,\n",
      "        38.3603, 39.9928, 37.7698, 38.0280, 38.4575, 37.7668, 38.6474, 38.6283,\n",
      "        39.8526, 39.0540, 38.7025, 39.1345, 38.8375, 38.9425, 39.1064, 36.9151,\n",
      "        37.8475, 38.1966, 37.7113, 40.1828, 38.8350, 37.3739, 39.5367, 38.1870,\n",
      "        38.1092, 37.1244, 40.7731, 39.1803, 39.3679, 38.6824, 38.1539, 38.7871,\n",
      "        37.4372, 39.9459, 38.0679, 39.0463, 37.8529, 38.8357, 40.0756, 38.8723,\n",
      "        40.1756, 39.8180, 37.8078, 38.4018, 39.3823, 39.0844, 38.6724, 39.5859,\n",
      "        38.2914, 39.5215, 39.1170, 37.4930, 38.0694, 38.9846, 41.1659, 39.2751,\n",
      "        40.1057, 37.6687, 39.5157, 38.9555, 38.9388, 38.4872, 38.4044, 39.3925,\n",
      "        38.6349, 38.4290, 38.4502, 40.0572, 38.4597, 39.3276, 39.9205, 38.3238,\n",
      "        38.6703, 38.4914, 39.0981, 37.3213, 38.7350, 38.7301, 38.3088, 39.1903,\n",
      "        39.3949, 39.7114, 38.7831, 38.5120, 39.3947, 38.8894, 37.8173, 38.9199,\n",
      "        39.5277, 39.1084, 39.0300, 38.8524, 37.7385, 39.8724, 39.9868, 39.7290,\n",
      "        38.3001, 39.6582, 37.6714, 39.3414, 39.0371, 38.2097, 39.9037, 39.0254,\n",
      "        38.8346, 38.8808, 40.0332, 39.6544, 39.5414, 39.6625, 38.5363, 37.9153,\n",
      "        39.1875, 38.6929, 38.7435, 38.5474, 39.8236, 39.3113, 39.8011, 40.2414,\n",
      "        40.1861, 38.2523, 39.2324, 37.9271, 40.4468, 39.2484, 37.9216, 39.0402,\n",
      "        40.2038, 39.2470, 38.8987, 40.1046, 39.0892, 38.6536, 39.9461, 38.9268,\n",
      "        38.3177, 38.0462, 38.3746, 39.2240, 38.1568, 38.3316, 39.2682, 39.3327,\n",
      "        39.2264, 39.1608, 39.3188, 38.2640, 37.5901, 39.9673, 39.4341, 39.5279,\n",
      "        39.4397, 39.3812, 39.2824, 39.8855, 38.1390, 37.8894, 39.1463, 39.7670,\n",
      "        39.7145, 38.4616, 38.7699, 39.4071, 38.0032, 38.3672, 40.2736, 38.9259,\n",
      "        39.9836, 39.3511, 38.1377, 39.5843, 38.7686, 38.2665, 40.1041, 37.9417,\n",
      "        37.9960, 39.3953, 38.2415, 39.1535, 39.2343, 37.9228, 38.2954, 40.4204,\n",
      "        39.5123, 38.4144, 40.6086, 38.5446, 38.5902, 38.0180, 37.9208, 37.3743,\n",
      "        39.4995, 39.9522, 38.5742, 39.5853, 40.0573, 39.4249, 37.3980, 37.9397,\n",
      "        38.6356, 38.4298, 38.8384, 39.1980, 38.3078, 39.6325, 40.0551, 39.6401,\n",
      "        38.6878, 39.8872, 38.7753, 38.4557, 38.4708, 38.8683, 38.5745, 38.4900,\n",
      "        39.8550, 38.9523, 38.8984, 39.7022, 38.9757, 38.9377, 38.6665, 39.1288,\n",
      "        37.4358, 38.4497, 39.1786, 38.8674, 39.1737, 39.5219, 39.8797, 37.4562,\n",
      "        37.8530, 38.8777, 38.6521, 38.1533, 39.8837, 37.5002, 37.8428, 39.8054,\n",
      "        38.8044, 37.8988, 38.9019, 39.3849, 38.9271, 38.6505, 38.4207, 39.5595,\n",
      "        38.4945, 38.7203, 37.8471, 39.2658, 38.2392, 39.0665, 39.3914, 40.2827,\n",
      "        37.6841, 38.7825, 39.7403, 37.6011, 39.3520, 37.2824, 38.5687, 39.1845,\n",
      "        38.7203, 37.8412, 39.6381, 39.3364, 39.1566, 38.0822, 38.9059, 39.2026])\n",
      "threshold value is 38.49038963317871\n",
      "layers.6.conv2.weight\n",
      "score list\n",
      "tensor([76.1064, 78.1820, 77.0876, 79.2719, 78.9822, 77.9937, 80.2668, 78.0234,\n",
      "        77.4451, 76.7871, 76.8851, 76.7233, 76.8217, 78.0269, 78.4786, 76.3915,\n",
      "        77.6786, 77.9866, 79.6524, 77.5151, 78.3309, 77.9799, 76.5543, 78.4562,\n",
      "        78.5576, 77.7057, 76.3253, 77.9373, 76.7035, 77.6852, 77.4539, 77.6584,\n",
      "        77.9429, 72.9491, 76.4728, 77.0062, 78.1714, 78.8962, 79.2404, 75.9305,\n",
      "        77.5395, 76.4808, 76.4167, 78.0302, 76.2593, 77.2755, 77.6939, 77.3900,\n",
      "        78.0091, 76.0415, 78.0690, 76.4217, 77.0743, 78.6627, 76.4589, 78.3129,\n",
      "        76.7822, 76.4617, 77.7361, 76.8360, 76.2381, 78.2614, 78.2258, 76.7298,\n",
      "        76.4451, 77.3757, 78.8445, 78.2788, 78.8441, 74.8891, 76.5697, 78.4305,\n",
      "        77.2389, 76.4725, 77.0537, 76.3795, 77.2064, 74.8999, 75.6409, 75.6416,\n",
      "        76.0814, 75.5939, 76.7047, 80.2097, 77.4068, 76.3893, 75.5737, 76.3322,\n",
      "        77.2166, 76.8534, 76.9436, 77.9675, 75.2570, 78.3419, 77.4123, 78.6837,\n",
      "        78.0868, 77.1892, 76.8167, 77.1339, 77.1648, 77.0675, 77.5224, 77.3535,\n",
      "        77.3051, 76.9607, 77.0447, 78.0379, 77.1156, 77.0032, 78.8271, 78.1989,\n",
      "        77.7451, 77.8851, 78.2974, 77.4080, 79.3088, 77.2971, 79.3799, 77.8512,\n",
      "        77.1156, 77.8764, 75.6988, 76.6283, 80.1742, 77.4342, 78.0559, 77.0426,\n",
      "        77.7765, 76.9121, 76.3530, 78.1646, 77.3105, 78.6427, 76.3980, 77.6151,\n",
      "        77.3059, 78.0291, 76.3591, 77.4294, 76.5286, 79.5655, 76.5795, 77.7497,\n",
      "        76.3647, 78.0788, 77.9855, 75.4137, 77.8883, 74.9192, 78.5684, 76.2940,\n",
      "        76.3295, 77.6023, 78.5380, 77.8869, 77.2490, 77.7670, 76.3813, 75.7824,\n",
      "        76.3352, 79.1409, 77.8865, 78.4797, 76.1356, 77.0686, 77.2122, 77.9026,\n",
      "        75.7660, 77.0261, 76.5153, 76.5717, 77.8550, 75.0817, 78.2174, 77.0259,\n",
      "        76.9353, 78.3653, 78.2082, 77.1979, 77.0708, 75.7183, 76.2421, 76.9961,\n",
      "        77.2804, 79.9520, 77.2045, 76.4338, 79.1440, 76.9562, 76.4162, 80.0371,\n",
      "        77.4507, 74.4924, 77.5833, 78.9822, 77.8673, 74.9395, 76.4843, 75.6703,\n",
      "        80.0648, 77.0023, 76.7050, 76.0007, 79.8980, 76.8145, 78.5102, 78.0869,\n",
      "        76.3630, 78.2270, 77.6991, 76.8819, 76.7300, 78.4317, 78.4245, 78.6394,\n",
      "        76.7664, 77.5462, 76.3618, 78.1888, 77.0876, 77.0525, 76.4206, 77.5738,\n",
      "        75.5386, 74.3888, 77.5672, 79.1543, 77.0393, 77.4433, 74.7670, 76.1151,\n",
      "        75.7178, 76.7383, 76.6279, 77.3597, 77.7226, 76.6629, 78.3651, 73.7565,\n",
      "        78.4054, 77.8468, 78.1704, 77.4860, 75.4688, 76.7952, 76.9914, 76.7790,\n",
      "        75.5349, 75.9334, 79.8360, 77.1199, 77.5430, 76.1845, 77.8176, 77.2358,\n",
      "        76.7308, 78.8669, 76.2358, 75.7545, 77.7155, 76.3128, 75.5155, 78.6705,\n",
      "        76.4321, 76.7620, 76.5271, 77.6808, 78.9089, 76.4477, 76.1909, 77.2903,\n",
      "        76.2599, 78.4916, 76.5529, 76.2888, 74.7101, 79.2090, 76.0021, 75.6734,\n",
      "        78.9191, 78.1525, 77.9535, 75.2214, 77.5529, 79.7178, 76.9273, 78.9766,\n",
      "        79.7120, 78.1360, 77.0437, 76.4296, 76.4599, 78.3837, 76.3283, 77.3333,\n",
      "        78.3854, 76.5912, 76.3897, 78.3573, 76.8249, 77.4292, 78.6023, 77.7556,\n",
      "        76.3059, 78.0423, 77.0966, 76.2576, 77.6996, 77.5193, 77.5338, 75.9775,\n",
      "        77.8167, 79.5561, 78.1952, 77.3111, 78.4921, 74.1353, 76.9398, 75.4276,\n",
      "        74.9481, 77.7200, 78.1506, 75.5113, 77.7850, 74.8308, 75.9737, 76.7465,\n",
      "        76.5650, 77.4589, 77.8884, 76.9423, 77.9636, 76.2834, 77.5529, 75.7785,\n",
      "        78.2715, 79.1603, 75.9660, 76.8380, 76.1940, 77.6840, 78.5042, 76.3034,\n",
      "        77.6323, 77.5411, 77.7580, 76.0022, 76.1110, 75.5941, 78.3643, 77.4682,\n",
      "        76.4401, 77.3797, 77.8956, 77.8915, 75.8838, 78.1635, 77.8349, 77.6542,\n",
      "        76.7404, 77.2497, 77.4924, 77.0447, 77.1667, 78.0949, 77.1565, 76.7250,\n",
      "        76.7273, 78.4443, 75.8992, 78.1333, 77.6489, 78.5359, 76.4070, 77.3792,\n",
      "        76.0514, 77.6943, 77.0416, 78.0742, 77.3330, 73.8747, 76.4332, 76.3967,\n",
      "        78.0877, 76.9522, 78.1876, 74.1799, 78.3619, 76.3165, 78.2811, 77.2856,\n",
      "        77.7592, 75.7171, 77.9841, 75.9792, 78.6094, 77.5179, 77.7273, 75.9626,\n",
      "        77.5858, 75.6633, 80.1249, 75.8456, 77.3325, 78.2998, 77.9377, 77.6895,\n",
      "        78.0500, 75.3369, 75.8809, 78.4593, 78.8597, 77.1519, 76.5663, 76.5795,\n",
      "        76.3058, 76.8942, 75.6091, 76.9301, 77.9671, 77.7260, 77.9486, 76.8976,\n",
      "        76.3897, 76.8452, 76.5561, 78.4405, 74.8935, 78.1197, 75.5979, 76.5477,\n",
      "        77.9020, 78.2442, 75.7343, 75.8631, 75.3019, 76.6787, 77.1231, 76.9788,\n",
      "        76.7783, 76.4988, 76.0764, 76.0277, 76.4104, 76.8035, 76.5135, 77.7501,\n",
      "        76.9409, 79.1647, 77.1329, 78.2483, 77.6251, 77.2451, 76.8138, 75.8938,\n",
      "        76.4545, 76.3964, 77.8341, 79.4508, 75.2710, 76.9467, 76.3390, 74.9475,\n",
      "        76.2850, 76.5172, 76.6587, 77.9104, 77.3418, 79.3238, 80.2674, 77.7172,\n",
      "        79.4217, 77.2971, 80.2874, 77.5828, 77.2457, 78.6684, 75.4252, 77.4930,\n",
      "        77.7544, 78.1968, 76.7094, 75.8045, 77.0182, 77.9029, 77.2955, 77.3312,\n",
      "        76.2252, 76.9668, 75.8959, 77.6943, 77.3437, 77.1281, 76.0772, 78.0739,\n",
      "        77.7791, 78.4766, 75.1976, 77.0718, 76.0193, 77.2507, 77.0963, 79.1166,\n",
      "        76.7074, 76.5397, 76.2340, 76.4810, 77.8370, 78.6119, 74.5123, 76.4885])\n",
      "threshold value is 76.55483627319336\n",
      "layers.7.conv2.weight\n",
      "score list\n",
      "tensor([76.2212, 76.7428, 75.1706, 77.7053, 79.0282, 76.9786, 76.4787, 76.3267,\n",
      "        77.0361, 76.5054, 77.4268, 78.7394, 77.9483, 76.8064, 77.8477, 79.9289,\n",
      "        77.7939, 78.9461, 75.5983, 77.5757, 78.1810, 75.8382, 77.3784, 77.6401,\n",
      "        78.0149, 76.5876, 76.6583, 76.4095, 76.4082, 78.5988, 74.9798, 77.0225,\n",
      "        76.0966, 76.8153, 78.3446, 74.6361, 78.4377, 76.7637, 76.8027, 76.4571,\n",
      "        77.9049, 78.2863, 77.6457, 76.3842, 78.3823, 76.4508, 77.6888, 76.6983,\n",
      "        76.4376, 76.4366, 76.7064, 76.2779, 77.7681, 78.3399, 77.9825, 77.5806,\n",
      "        78.3742, 75.3523, 77.4958, 76.8807, 76.3350, 76.3290, 78.7966, 74.6237,\n",
      "        75.9995, 76.6564, 75.8269, 76.8401, 76.3860, 77.0191, 75.9422, 78.1884,\n",
      "        76.9520, 76.2006, 78.3752, 77.8328, 77.4488, 76.7785, 77.5879, 77.7776,\n",
      "        77.0071, 78.2892, 77.6456, 78.0466, 79.9821, 75.7286, 77.6389, 77.7622,\n",
      "        76.5708, 78.8082, 78.4709, 78.2039, 78.8599, 77.9045, 78.7753, 76.4999,\n",
      "        77.5641, 77.3111, 78.1683, 76.8876, 77.3442, 75.6876, 75.6721, 77.3349,\n",
      "        77.6817, 76.2638, 77.1339, 77.2583, 77.8620, 77.1813, 77.4743, 77.2788,\n",
      "        79.1009, 76.6976, 80.2344, 77.4115, 74.5366, 77.7372, 79.5966, 76.1638,\n",
      "        77.9554, 78.3014, 76.6797, 78.7442, 74.3352, 76.6188, 76.7053, 77.8712,\n",
      "        78.6705, 76.5200, 76.1193, 75.9238, 77.4345, 76.5870, 78.8028, 73.8113,\n",
      "        79.3070, 77.5957, 76.9687, 75.9886, 75.8965, 77.6214, 78.8129, 78.0705,\n",
      "        79.9485, 77.1545, 75.1321, 77.3693, 77.6919, 75.3659, 78.2938, 75.5773,\n",
      "        75.3677, 77.5644, 77.1084, 76.4917, 76.1627, 76.1058, 77.8532, 73.3107,\n",
      "        76.9924, 79.5024, 76.3787, 76.3526, 78.6382, 75.3423, 77.3622, 75.4449,\n",
      "        78.4327, 75.3411, 75.5054, 76.6380, 78.0253, 76.6405, 77.5369, 77.1275,\n",
      "        78.0770, 78.0360, 78.1733, 77.8826, 78.2006, 77.5072, 74.4677, 76.9978,\n",
      "        75.3688, 78.0902, 78.5796, 77.4872, 79.1259, 75.6640, 75.9733, 78.3236,\n",
      "        76.5384, 78.3944, 76.2542, 78.3361, 78.2848, 76.9063, 78.2134, 77.7607,\n",
      "        76.7512, 77.3471, 78.4709, 77.1328, 76.1925, 77.6219, 78.2746, 73.5120,\n",
      "        77.2843, 76.2169, 77.6637, 78.1146, 78.9288, 79.4970, 75.2931, 78.6263,\n",
      "        77.5769, 76.6018, 76.9926, 76.8538, 77.2421, 77.8365, 78.0311, 76.7172,\n",
      "        75.6825, 77.0434, 80.5494, 78.3959, 74.9405, 77.9368, 75.6807, 76.6703,\n",
      "        75.7741, 76.2624, 77.2222, 75.9872, 77.5527, 76.3405, 75.7321, 77.8327,\n",
      "        75.5922, 75.8379, 77.3355, 77.6834, 75.7878, 75.7914, 76.6523, 76.8492,\n",
      "        75.3407, 78.4246, 77.2089, 75.1364, 79.0326, 77.6509, 74.6600, 77.7244,\n",
      "        78.0433, 78.2949, 74.8760, 73.9049, 76.1164, 77.8036, 76.8954, 77.4907,\n",
      "        75.8823, 78.4970, 78.9686, 76.9565, 78.0508, 75.4085, 80.2128, 77.8448,\n",
      "        75.6664, 77.3466, 77.6708, 76.5325, 78.2893, 77.9247, 77.8603, 78.1601,\n",
      "        78.5241, 75.8652, 78.1918, 77.1116, 77.3541, 76.0911, 76.7017, 77.2856,\n",
      "        76.2556, 79.2159, 76.5884, 78.4050, 78.3944, 77.9702, 77.0277, 79.1784,\n",
      "        77.7744, 78.8065, 78.2915, 77.0358, 75.8324, 78.5029, 75.1177, 76.1902,\n",
      "        78.4159, 76.1681, 78.5113, 78.7346, 76.8858, 77.3493, 76.6917, 78.0583,\n",
      "        78.1389, 77.6802, 77.0569, 79.5172, 77.6480, 78.0564, 77.2672, 77.8546,\n",
      "        78.4215, 77.3297, 77.2398, 77.2513, 77.5059, 77.8990, 78.0321, 77.1378,\n",
      "        79.5414, 78.1032, 75.6576, 79.7734, 77.9237, 77.9173, 78.1068, 77.1834,\n",
      "        77.0764, 76.7443, 77.2783, 77.6809, 75.2076, 77.4540, 76.2492, 77.9779,\n",
      "        78.1300, 75.7851, 75.9825, 78.2854, 75.7998, 76.0697, 75.3268, 76.2818,\n",
      "        76.6781, 77.3364, 77.2828, 77.3452, 78.1448, 75.9328, 76.9443, 78.9074,\n",
      "        77.4691, 78.7476, 77.3442, 78.6339, 77.0516, 77.2063, 77.1229, 77.4715,\n",
      "        78.4874, 77.5574, 78.6693, 74.5807, 77.0469, 76.0123, 76.3352, 75.4907,\n",
      "        77.4259, 77.2737, 76.7403, 78.1534, 75.9454, 75.7375, 78.9247, 77.4149,\n",
      "        75.7210, 78.6285, 78.2244, 77.0954, 78.6041, 76.6577, 77.1336, 78.3360,\n",
      "        76.0464, 74.9379, 77.5097, 79.4939, 76.2339, 76.0396, 76.9661, 75.6850,\n",
      "        77.6419, 77.7621, 75.5589, 76.0146, 76.4126, 77.0749, 76.1345, 78.6157,\n",
      "        77.2090, 77.4904, 76.5832, 77.6732, 77.0951, 77.1187, 78.2112, 77.0318,\n",
      "        76.7099, 77.7290, 79.0865, 78.2748, 77.0548, 76.1088, 76.0855, 76.9447,\n",
      "        77.8579, 74.0576, 76.4441, 77.2622, 75.4915, 77.7440, 77.8327, 78.0630,\n",
      "        77.8416, 76.6731, 76.1305, 77.2112, 78.4831, 78.0226, 77.3325, 77.6971,\n",
      "        75.3728, 77.7359, 77.1531, 75.4077, 79.6452, 76.2868, 76.1222, 79.5969,\n",
      "        79.0380, 78.3671, 78.4434, 78.3245, 77.8341, 77.0548, 77.6202, 76.5981,\n",
      "        75.8321, 76.9978, 76.5074, 77.9723, 77.2915, 75.7463, 76.7608, 76.5973,\n",
      "        77.3506, 76.5729, 78.6472, 76.8939, 74.0707, 76.0441, 78.0015, 77.4627,\n",
      "        76.0146, 75.7814, 77.1929, 76.8741, 76.8316, 76.8798, 76.5495, 76.7855,\n",
      "        79.1238, 78.4338, 78.9859, 77.9715, 79.2542, 77.9337, 79.0008, 76.5859,\n",
      "        74.3411, 77.7776, 77.8974, 77.4526, 77.5440, 80.2018, 77.6689, 78.6351,\n",
      "        80.1946, 75.3932, 79.2985, 77.3433, 76.1887, 78.0173, 76.6517, 76.7912,\n",
      "        75.7751, 75.8224, 76.4106, 80.1185, 80.1989, 77.3060, 76.5238, 79.4682])\n",
      "threshold value is 76.59919967651368\n",
      "layers.8.conv2.weight\n",
      "score list\n",
      "tensor([78.0884, 76.7215, 74.1634, 76.3501, 78.2558, 76.8615, 77.2575, 75.0113,\n",
      "        75.9393, 75.2012, 79.5895, 74.4374, 75.3284, 76.2033, 77.1677, 75.5233,\n",
      "        77.0295, 75.7742, 77.7442, 78.5127, 77.7504, 75.1099, 75.8276, 78.1201,\n",
      "        79.1436, 78.3137, 77.4649, 75.1662, 76.6960, 75.5332, 76.8269, 76.9244,\n",
      "        75.7302, 75.2562, 75.9575, 75.7261, 77.1805, 76.3473, 77.6094, 77.5900,\n",
      "        76.0449, 77.2959, 73.3690, 76.0292, 76.8381, 74.5527, 77.7799, 77.7947,\n",
      "        76.3277, 75.2367, 76.9305, 75.8792, 74.6082, 77.8215, 76.8276, 77.8461,\n",
      "        76.8586, 76.1436, 76.6512, 77.0909, 78.6106, 76.2944, 78.1425, 76.4335,\n",
      "        75.2962, 78.8929, 75.5409, 75.2871, 77.0082, 75.1552, 74.1921, 75.0537,\n",
      "        76.7760, 77.7291, 75.9770, 75.9643, 74.4520, 75.8969, 77.9750, 77.0326,\n",
      "        78.4973, 76.8515, 76.1501, 74.3080, 77.2457, 75.9631, 78.5394, 77.1818,\n",
      "        78.2200, 75.5303, 77.5946, 74.1038, 77.0807, 77.6323, 75.3849, 75.7099,\n",
      "        76.9771, 75.6056, 75.3559, 75.7962, 76.8146, 76.8873, 77.7474, 76.3824,\n",
      "        75.0884, 77.0923, 78.8790, 78.5058, 75.3731, 77.6090, 78.5317, 74.6649,\n",
      "        78.3146, 75.4907, 79.6413, 77.4475, 77.0618, 76.1852, 76.7620, 75.9602,\n",
      "        76.9743, 77.3348, 79.4125, 78.5618, 73.6285, 77.5766, 76.5703, 79.5794,\n",
      "        76.2008, 76.3677, 79.5055, 75.3495, 77.5087, 76.8354, 77.0115, 77.7880,\n",
      "        73.7319, 75.2410, 76.0317, 76.0150, 77.4280, 77.2655, 76.5868, 76.6155,\n",
      "        75.1285, 77.4242, 78.4497, 79.6375, 76.3216, 78.8841, 78.9759, 76.8018,\n",
      "        77.4663, 76.4304, 77.3173, 75.1820, 74.8300, 77.9425, 76.9492, 76.2235,\n",
      "        77.2202, 78.2003, 75.8936, 76.4616, 73.3457, 76.9897, 77.9525, 76.9872,\n",
      "        75.0422, 76.1268, 77.0514, 79.3372, 78.8305, 78.9297, 77.4507, 77.7539,\n",
      "        77.3249, 75.9209, 75.3452, 77.2949, 76.5592, 76.5483, 77.3314, 76.4735,\n",
      "        76.7957, 76.1487, 75.2829, 77.1167, 77.0185, 76.3874, 77.1774, 78.1687,\n",
      "        77.9381, 77.6059, 76.4660, 77.2720, 75.7220, 77.6134, 76.4168, 75.8425,\n",
      "        76.2906, 77.1503, 77.4656, 76.1792, 78.1232, 76.6146, 79.7294, 78.3195,\n",
      "        77.6247, 74.4284, 76.0282, 81.8550, 75.9307, 77.9815, 75.7305, 75.0206,\n",
      "        76.7480, 75.9371, 75.8984, 76.8021, 75.7190, 76.6419, 76.6787, 78.1430,\n",
      "        76.0735, 76.9481, 77.9514, 75.3745, 78.1985, 76.4756, 77.1162, 77.4978,\n",
      "        76.5535, 77.8275, 76.1204, 78.3201, 77.3371, 74.8035, 76.1158, 78.0501,\n",
      "        76.2380, 78.3947, 78.9161, 76.4890, 78.9190, 74.7070, 77.5645, 78.0445,\n",
      "        79.3050, 74.0673, 75.5983, 78.0702, 76.1489, 78.0969, 75.8785, 78.2392,\n",
      "        77.2530, 77.5448, 77.3168, 75.1330, 76.4678, 76.4551, 76.4991, 76.3254,\n",
      "        75.5677, 74.1537, 77.5805, 79.8732, 76.4033, 73.8831, 78.2222, 76.1986,\n",
      "        76.0877, 77.9891, 78.9221, 75.1157, 77.3203, 78.9042, 76.0636, 76.8168,\n",
      "        76.3331, 76.6811, 76.0643, 77.4000, 78.1768, 74.8865, 75.6133, 76.3210,\n",
      "        76.0753, 75.3349, 76.2946, 78.7380, 72.8355, 75.2820, 73.6723, 77.9270,\n",
      "        76.4951, 74.5603, 76.9976, 76.0465, 78.7794, 76.7510, 76.9993, 76.9925,\n",
      "        75.2787, 79.9227, 79.3637, 78.1994, 78.2362, 77.3065, 75.8345, 77.5964,\n",
      "        77.0953, 77.7955, 75.3961, 77.4365, 75.3133, 74.9634, 76.7346, 76.6261,\n",
      "        74.9529, 75.7388, 76.8427, 77.7531, 76.4951, 76.0298, 77.4000, 75.7726,\n",
      "        77.5245, 76.5514, 78.4021, 77.9859, 76.4212, 76.4947, 79.0158, 77.6690,\n",
      "        75.7422, 76.4513, 76.2869, 77.1719, 75.4389, 77.5803, 77.7455, 76.7559,\n",
      "        77.9860, 77.9664, 76.9443, 76.7876, 76.9173, 74.5414, 77.7312, 78.3365,\n",
      "        76.6902, 76.5385, 78.0918, 76.8572, 77.8664, 77.4771, 77.1923, 76.8879,\n",
      "        76.9741, 76.1924, 76.2939, 76.3565, 75.2752, 78.2428, 76.9658, 75.3519,\n",
      "        75.9496, 75.2847, 76.1587, 75.7807, 74.5223, 77.5787, 76.5314, 74.3698,\n",
      "        78.6984, 75.6038, 77.1552, 77.0140, 79.5438, 76.2321, 77.4439, 74.8713,\n",
      "        76.1546, 75.4380, 75.4357, 74.4306, 76.0067, 76.1214, 78.1050, 79.7161,\n",
      "        77.7328, 77.9345, 78.5736, 77.0576, 79.2977, 76.1933, 76.4321, 74.4451,\n",
      "        77.3997, 75.6611, 76.3056, 77.9956, 77.6162, 75.3435, 73.8616, 77.7456,\n",
      "        77.3954, 76.4107, 75.6909, 77.6238, 76.6627, 75.8976, 80.4582, 75.1246,\n",
      "        76.0470, 79.1738, 77.3652, 78.1984, 77.2377, 75.0663, 77.2985, 76.7801,\n",
      "        76.7039, 75.1946, 78.4644, 76.8348, 76.9999, 76.2343, 76.6365, 77.2778,\n",
      "        77.5738, 77.1406, 75.2607, 77.1077, 77.3262, 76.8892, 78.1605, 74.1344,\n",
      "        75.9908, 77.3353, 77.9365, 73.7895, 78.5738, 75.6983, 76.9966, 76.0379,\n",
      "        76.4398, 74.8284, 75.8617, 78.6728, 74.3161, 80.4792, 76.6292, 76.2491,\n",
      "        76.9913, 74.4194, 78.8635, 75.3427, 76.1450, 76.4752, 75.2590, 76.7592,\n",
      "        76.2561, 74.9535, 76.0730, 76.1540, 77.8549, 78.1999, 76.6690, 77.5231,\n",
      "        77.4274, 78.1729, 77.9562, 77.7552, 77.4023, 77.1452, 76.5091, 78.7479,\n",
      "        79.8142, 77.8903, 75.7770, 76.8245, 76.9591, 79.3236, 75.4424, 76.4163,\n",
      "        77.2713, 78.1656, 75.9011, 77.3630, 76.0913, 76.2704, 75.6504, 77.4749,\n",
      "        76.1053, 75.1729, 75.9239, 78.0523, 79.2067, 78.3796, 77.3328, 75.8486,\n",
      "        77.2366, 77.9235, 75.9315, 77.6771, 75.2143, 76.7918, 77.9228, 76.2011])\n",
      "threshold value is 76.08876495361328\n",
      "layers.9.conv2.weight\n",
      "score list\n",
      "tensor([74.9580, 74.4483, 73.5933, 75.5912, 74.8363, 75.3842, 76.8324, 74.9566,\n",
      "        73.0747, 75.6770, 76.4046, 75.9329, 74.1720, 73.2849, 76.4769, 76.2630,\n",
      "        76.6686, 76.3158, 74.3016, 77.0776, 75.1849, 75.3683, 74.8706, 76.5271,\n",
      "        73.5207, 75.8805, 75.5948, 77.5556, 78.0025, 76.8967, 72.3828, 77.0513,\n",
      "        74.8928, 74.6816, 74.5426, 76.4732, 75.2522, 75.7739, 75.4932, 75.1668,\n",
      "        76.2777, 77.3519, 78.4993, 74.4550, 76.5664, 73.1041, 74.4761, 75.8398,\n",
      "        74.0484, 77.7089, 75.8315, 75.2361, 77.7435, 72.4014, 74.6377, 80.0647,\n",
      "        76.8908, 74.5820, 76.4812, 76.8731, 76.8060, 72.8265, 72.3836, 76.9236,\n",
      "        74.4234, 74.0290, 75.2989, 74.2112, 74.4631, 73.7432, 78.1328, 78.2660,\n",
      "        76.9184, 75.3799, 73.5973, 76.8919, 78.9486, 74.4790, 75.0722, 74.1012,\n",
      "        76.0726, 74.3967, 77.7097, 74.2284, 74.8338, 76.2935, 76.7811, 76.7049,\n",
      "        74.6840, 75.0401, 74.8657, 75.4514, 74.3127, 76.3533, 74.8008, 77.6380,\n",
      "        75.3105, 74.1959, 76.6885, 78.4516, 74.3935, 74.3124, 75.7016, 76.0707,\n",
      "        78.2674, 75.2059, 73.4598, 75.9806, 77.3141, 75.1653, 75.8493, 76.9623,\n",
      "        75.4075, 76.3367, 75.7448, 75.8006, 73.4694, 75.4288, 75.0871, 76.7925,\n",
      "        72.7362, 76.8026, 77.0831, 73.3355, 74.8255, 76.0128, 76.1790, 74.2128,\n",
      "        73.6244, 76.0301, 76.5877, 77.7261, 76.3317, 75.9756, 76.3530, 75.3577,\n",
      "        77.0679, 76.7353, 76.8634, 77.9066, 74.2590, 76.9216, 74.6988, 78.8945,\n",
      "        77.2122, 75.4048, 75.9898, 77.2573, 75.6693, 72.7823, 76.0947, 79.1763,\n",
      "        74.1563, 77.1827, 75.5723, 76.1901, 75.4992, 75.5203, 78.0747, 75.2090,\n",
      "        75.7772, 75.4780, 77.2945, 76.3293, 74.2505, 74.6684, 75.2348, 76.8766,\n",
      "        75.5035, 76.0846, 76.4274, 74.7192, 72.6872, 74.8256, 75.4943, 75.7539,\n",
      "        76.6327, 75.7695, 75.2634, 78.4247, 74.2386, 77.4942, 75.0556, 77.4881,\n",
      "        76.8254, 76.4597, 77.6491, 77.0098, 74.0569, 78.1083, 77.7634, 75.6581,\n",
      "        75.6302, 76.4322, 75.8378, 74.9714, 76.0145, 74.2733, 72.7277, 76.4789,\n",
      "        78.4184, 76.4962, 72.9023, 78.7787, 76.7549, 75.5577, 76.0307, 76.1316,\n",
      "        77.9807, 76.8475, 74.4655, 76.6795, 75.9317, 72.6172, 78.2204, 76.9033,\n",
      "        76.4720, 75.2694, 75.9025, 73.7558, 76.7343, 76.4545, 76.2087, 76.7996,\n",
      "        74.8072, 76.2575, 77.4619, 74.1046, 73.4313, 75.7616, 78.6533, 74.9046,\n",
      "        76.3706, 75.7964, 76.7537, 73.1095, 75.3914, 76.3503, 73.7199, 74.6999,\n",
      "        76.7570, 78.2054, 76.9804, 73.3342, 75.5676, 73.3041, 72.6569, 75.8374,\n",
      "        74.6750, 76.5177, 74.4673, 75.0477, 74.4161, 74.4434, 75.7552, 77.0488,\n",
      "        75.6881, 74.7003, 75.4463, 76.2568, 77.2190, 77.5566, 77.3693, 74.2204,\n",
      "        75.2811, 74.1058, 76.4771, 77.1694, 76.0080, 74.6104, 77.9662, 78.6436,\n",
      "        75.9857, 75.7740, 76.4904, 76.9677, 76.1724, 75.1257, 75.4590, 76.5514,\n",
      "        73.4234, 75.9759, 75.0661, 76.1386, 75.8081, 78.1907, 72.6864, 78.0951,\n",
      "        76.5766, 74.9852, 76.7061, 76.2168, 73.6176, 76.8274, 77.4158, 76.1652,\n",
      "        75.4460, 73.6525, 77.3257, 77.1195, 76.3064, 76.8863, 77.1981, 76.4159,\n",
      "        75.1996, 75.7564, 75.4567, 76.3412, 76.1525, 76.0559, 75.1126, 76.9146,\n",
      "        76.8343, 75.6815, 74.1098, 75.9208, 78.0997, 76.6408, 75.2245, 76.7909,\n",
      "        75.5903, 76.2379, 75.0535, 75.1462, 74.0583, 76.6583, 75.7321, 74.6495,\n",
      "        76.2494, 78.2346, 73.8286, 74.9634, 75.7471, 78.7687, 76.9425, 77.9359,\n",
      "        76.7495, 77.8019, 75.5210, 78.0603, 76.1397, 77.7690, 72.5282, 75.8297,\n",
      "        78.2846, 75.3304, 76.1615, 75.9648, 76.1834, 75.5534, 75.9041, 75.0117,\n",
      "        76.2764, 75.8159, 71.0105, 76.3929, 75.3089, 73.1954, 75.7237, 77.2301,\n",
      "        74.6019, 77.2389, 77.3924, 76.4480, 78.6173, 73.3581, 76.7185, 74.5519,\n",
      "        74.7969, 73.3516, 74.3088, 75.6774, 75.9970, 76.6235, 76.4407, 76.5517,\n",
      "        77.8616, 76.3675, 76.5959, 77.2599, 75.7343, 77.4129, 75.9541, 75.7107,\n",
      "        76.5892, 77.8482, 76.9077, 75.7283, 71.2479, 72.3863, 76.9399, 75.6945,\n",
      "        75.5810, 78.0076, 75.9885, 74.8109, 74.1259, 76.2302, 75.2955, 76.0571,\n",
      "        74.5914, 75.7012, 79.2759, 73.1443, 76.9059, 76.3007, 73.6572, 75.0245,\n",
      "        77.4036, 74.7183, 76.2329, 77.7752, 74.8770, 77.3467, 75.6335, 76.4176,\n",
      "        75.5579, 74.0773, 76.6325, 74.1045, 77.1200, 76.2064, 75.3717, 74.4311,\n",
      "        76.9827, 75.7359, 75.5968, 76.0363, 77.0860, 76.5660, 75.8203, 76.5149,\n",
      "        76.9609, 73.5708, 74.8681, 75.7988, 73.8265, 77.6786, 72.2847, 75.7794,\n",
      "        75.1019, 75.6337, 76.8284, 74.2491, 75.7468, 76.5062, 75.7308, 77.6178,\n",
      "        77.7568, 75.1609, 74.3213, 74.8078, 74.0697, 76.0269, 76.0147, 76.6704,\n",
      "        78.4556, 76.5164, 78.1136, 74.1776, 77.0804, 74.0295, 77.1549, 75.4755,\n",
      "        77.4085, 74.8262, 74.2700, 75.0748, 76.2437, 75.5843, 77.5789, 77.2841,\n",
      "        74.7887, 77.9448, 77.3076, 76.1739, 74.5196, 74.0404, 73.6492, 74.6086,\n",
      "        76.0119, 76.8832, 76.7962, 75.5080, 76.8593, 74.9399, 74.8701, 75.4944,\n",
      "        78.7389, 76.3535, 73.9159, 76.8164, 76.5698, 76.5385, 76.4871, 75.5026,\n",
      "        76.1430, 77.3531, 74.9172, 74.9386, 75.9480, 74.0733, 72.9623, 79.0972,\n",
      "        75.6866, 75.7075, 75.6161, 75.8432, 75.1429, 75.8869, 73.9976, 72.7914])\n",
      "threshold value is 75.11654663085938\n",
      "layers.10.conv2.weight\n",
      "score list\n",
      "tensor([74.6281, 75.8425, 76.2822, 78.1362, 72.9758, 73.2126, 75.0649, 73.7444,\n",
      "        75.8118, 73.8073, 72.4769, 74.2471, 76.3181, 72.9075, 76.7209, 76.3600,\n",
      "        72.4541, 75.5694, 76.5970, 76.4001, 76.3550, 75.0402, 76.4662, 73.5785,\n",
      "        76.0532, 75.7881, 75.5611, 76.5108, 71.8316, 75.9141, 72.3329, 71.5909,\n",
      "        75.0538, 77.6420, 71.4501, 77.1169, 76.0344, 71.8545, 75.3439, 74.9057,\n",
      "        73.5372, 73.5411, 73.9915, 74.7554, 73.0321, 74.2317, 75.7496, 71.2486,\n",
      "        70.9082, 72.9245, 74.7531, 74.4899, 76.6410, 75.3730, 75.1274, 74.1061,\n",
      "        75.7921, 74.0321, 73.0068, 72.7977, 70.5614, 76.5137, 76.7355, 77.2387,\n",
      "        71.1808, 72.2728, 74.3940, 72.3244, 76.2013, 76.2759, 75.2342, 74.8808,\n",
      "        73.9182, 76.8884, 76.7179, 72.8003, 73.4700, 75.0548, 72.6618, 74.3029,\n",
      "        74.5103, 75.1239, 75.6544, 76.1634, 73.4988, 69.8606, 76.4998, 73.3983,\n",
      "        75.1172, 76.8188, 71.0489, 76.9240, 75.0871, 74.5637, 74.7777, 73.9422,\n",
      "        76.2546, 75.2205, 77.5444, 75.8573, 76.8701, 70.4931, 74.7039, 76.0951,\n",
      "        75.2021, 76.3737, 75.0334, 74.3266, 75.7349, 75.2178, 76.7012, 72.8847,\n",
      "        75.7266, 74.3364, 76.6966, 77.4325, 73.9156, 74.2720, 73.2388, 72.0277,\n",
      "        74.2493, 74.1036, 73.7944, 73.0257, 75.1955, 76.6816, 78.2654, 76.4096,\n",
      "        72.6718, 75.1671, 71.9790, 72.6877, 74.5979, 77.4316, 72.1468, 74.1987,\n",
      "        72.5971, 73.9468, 74.8903, 76.9421, 75.7880, 77.5495, 75.8042, 76.8114,\n",
      "        76.5163, 80.0644, 76.5890, 76.2647, 76.0506, 74.7409, 76.5979, 75.5589,\n",
      "        79.2514, 79.7411, 73.4914, 74.3040, 75.4297, 76.2489, 73.2865, 71.7760,\n",
      "        74.3310, 76.7906, 75.5441, 76.4425, 74.0627, 75.1903, 77.6575, 75.3435,\n",
      "        74.4697, 70.7444, 71.8577, 70.8445, 73.5012, 74.3412, 74.8110, 76.0629,\n",
      "        74.2972, 71.7772, 73.7627, 71.9654, 74.8670, 75.5775, 73.2744, 76.8797,\n",
      "        71.6353, 75.2290, 77.3177, 75.0844, 75.2484, 74.3773, 73.2721, 69.5836,\n",
      "        74.6379, 72.5802, 71.7894, 76.9044, 76.7221, 72.3944, 78.3140, 74.3008,\n",
      "        73.9095, 74.1057, 75.4072, 74.4141, 75.5078, 72.9428, 75.6634, 72.6075,\n",
      "        77.3780, 72.1226, 74.1888, 71.7213, 75.3393, 73.4198, 75.8165, 77.3378,\n",
      "        72.1548, 73.7257, 76.9023, 75.0366, 74.6594, 74.8546, 77.0460, 74.0794,\n",
      "        72.3835, 73.9219, 74.8036, 74.4257, 74.7558, 76.1846, 75.5217, 75.8000,\n",
      "        75.6157, 72.9181, 74.4195, 70.5646, 73.2272, 76.5699, 74.9868, 77.0595,\n",
      "        75.4823, 74.3951, 74.6301, 75.1332, 70.9812, 75.3751, 75.7406, 76.1333,\n",
      "        75.9999, 75.3507, 71.0601, 74.9748, 72.5622, 74.6583, 75.4793, 74.2766,\n",
      "        74.9154, 75.9082, 73.6714, 72.6119, 74.5750, 74.0308, 73.0918, 73.9467,\n",
      "        76.2311, 72.3654, 76.1777, 76.5593, 79.9625, 73.8881, 74.3644, 73.1885,\n",
      "        74.7457, 72.2265, 73.0604, 76.2003, 73.1010, 76.4927, 74.2031, 75.6305,\n",
      "        77.2468, 75.1123, 72.6887, 72.7370, 78.2182, 71.9433, 73.0903, 74.4900,\n",
      "        76.5479, 75.6396, 75.8899, 74.2993, 74.3090, 74.0265, 73.1499, 74.2993,\n",
      "        75.7060, 75.0351, 75.5414, 75.7810, 71.8730, 74.2862, 72.3497, 76.3445,\n",
      "        78.0230, 76.5236, 75.8787, 74.4866, 75.1140, 73.4752, 73.8163, 75.6014,\n",
      "        73.0248, 74.4807, 74.0785, 76.3627, 77.2398, 76.5146, 74.0118, 74.6790,\n",
      "        75.0450, 74.9995, 74.6901, 74.3697, 75.0978, 76.4550, 74.1395, 71.8077,\n",
      "        75.1713, 74.8123, 74.1557, 76.7817, 74.4059, 74.5067, 74.8746, 77.4798,\n",
      "        74.2895, 75.4295, 76.3354, 75.9721, 75.0942, 76.5007, 72.1428, 79.5648,\n",
      "        77.2982, 74.1592, 73.4331, 73.2137, 74.7288, 75.1742, 75.4056, 75.5847,\n",
      "        75.6639, 72.8238, 76.6661, 73.3209, 75.2686, 72.3951, 76.2649, 74.5207,\n",
      "        71.9091, 76.1878, 76.2996, 76.4663, 75.5179, 74.8644, 74.7491, 74.8639,\n",
      "        75.7163, 74.3536, 73.7456, 77.8332, 73.2546, 76.3373, 72.8730, 72.3979,\n",
      "        75.9343, 71.7424, 76.3824, 75.0721, 77.3128, 75.4617, 72.1522, 75.2379,\n",
      "        74.9477, 31.1533, 75.4204, 71.5107, 74.9474, 75.8565, 72.6215, 73.3988,\n",
      "        74.9529, 71.7579, 74.9947, 76.5461, 75.1301, 72.3110, 74.8419, 75.2358,\n",
      "        74.4176, 72.7706, 76.3606, 75.0191, 75.7663, 75.1688, 73.2949, 73.2350,\n",
      "        75.5814, 74.9004, 58.0336, 75.3648, 72.1077, 74.3726, 74.1920, 75.6592,\n",
      "        76.3840, 72.3668, 74.1207, 76.2811, 76.3068, 74.2028, 76.0547, 73.4330,\n",
      "        75.1879, 76.4872, 75.6228, 73.4877, 71.7048, 75.1772, 74.4212, 74.2260,\n",
      "        74.8464, 78.5287, 72.0853, 75.9713, 75.7357, 74.1665, 76.2025, 74.6007,\n",
      "        73.1128, 72.8868, 74.9493, 73.8187, 75.7603, 74.9555, 70.9471, 75.3532,\n",
      "        73.1232, 74.6770, 74.9753, 75.0498, 70.8853, 76.2048, 75.9926, 74.7082,\n",
      "        75.1293, 73.8412, 75.2838, 74.2010, 75.7088, 71.3973, 73.4796, 74.9360,\n",
      "        74.1553, 71.1790, 74.6707, 76.3542, 75.6241, 75.6420, 76.3527, 74.3093,\n",
      "        73.7361, 74.1461, 74.0607, 70.4890, 73.4255, 77.1535, 74.9423, 76.5976,\n",
      "        74.8789, 71.2750, 72.5927, 75.3641, 71.5810, 73.2048, 74.0247, 75.1420,\n",
      "        78.1505, 74.8258, 76.5048, 73.8732, 78.1504, 75.9782, 76.5797, 74.6655,\n",
      "        74.7253, 73.5905, 75.5862, 77.3048, 74.6991, 77.2120, 74.1011, 74.8286,\n",
      "        76.1235, 73.9971, 74.7588, 72.8712, 77.8487, 77.4154, 76.0115, 73.9808])\n",
      "threshold value is 74.01570739746093\n",
      "layers.11.conv2.weight\n",
      "score list\n",
      "tensor([74.5278, 70.1573, 70.3922,  ..., 70.5870, 72.4839, 69.6722])\n",
      "threshold value is 70.27001342773437\n",
      "layers.12.conv2.weight\n",
      "score list\n",
      "tensor([147.5624, 114.1982, 141.6789,  ..., 144.7000, 147.6284, 130.8778])\n",
      "threshold value is 129.04012908935547\n",
      "about to apply mask\n",
      "param shape\n",
      "torch.Size([32, 3, 3, 3])\n",
      "mask dict name shape\n",
      "torch.Size([32, 3, 3, 3])\n",
      "param shape\n",
      "torch.Size([64, 32, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([64, 32, 1, 1])\n",
      "param shape\n",
      "torch.Size([128, 64, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([128, 64, 1, 1])\n",
      "param shape\n",
      "torch.Size([128, 128, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([128, 128, 1, 1])\n",
      "param shape\n",
      "torch.Size([256, 128, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([256, 128, 1, 1])\n",
      "param shape\n",
      "torch.Size([256, 256, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([256, 256, 1, 1])\n",
      "param shape\n",
      "torch.Size([512, 256, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([512, 256, 1, 1])\n",
      "param shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "param shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "param shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "param shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "param shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([512, 512, 1, 1])\n",
      "param shape\n",
      "torch.Size([1024, 512, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([1024, 512, 1, 1])\n",
      "param shape\n",
      "torch.Size([1024, 1024, 1, 1])\n",
      "mask dict name shape\n",
      "torch.Size([1024, 1024, 1, 1])\n",
      "about to remove channel\n"
     ]
    }
   ],
   "source": [
    "for prune_thres in [0.3]:\n",
    "    print(prune_thres)\n",
    "    print(\"about to fraction prune\")\n",
    "    new_model = copy.deepcopy(model)\n",
    "    channel_fraction_pruning(new_model, prune_thres)\n",
    "    # break\n",
    "    print(\"about to apply mask\")\n",
    "    new_model._apply_mask()\n",
    "    # break\n",
    "    print(\"about to remove channel\")\n",
    "    new_model = mb_pt.remove_channel(new_model)\n",
    "    # summary(new_model, (3, 32, 32))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(new_model)\n",
    "# 1590857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/mb_cifar10')\n",
    "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=128,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # images = Variable(images.view(-1, 1, 28, 28)).to(torch.device('cuda'))\n",
    "            images = Variable(images.view(-1, 3, 32, 32)).to(torch.device('cpu'))\n",
    "            labels = Variable(labels).to(torch.device('cpu'))\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = correct.float() / total\n",
    "    writer.add_scalar(\"test_accuracy\", accuracy)\n",
    "    # print(, Test accuracy={100*accuracy.data.item():.4f}\")\n",
    "    # test_acc.append(100 * accuracy)\n",
    "    return 100*accuracy.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.809999823570251"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = test(new_model)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion_sum = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "def train(epoch, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    global iteration\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images = Variable(images.view(-1,1,28,28)).to(torch.device('cuda'))\n",
    "        images = Variable(images.view(-1,3,32,32)).to(torch.device('cpu'))\n",
    "\n",
    "        labels = Variable(labels).to(torch.device('cpu'))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f' % (epoch+1, 5, i+1, len(train_dataset)//128, loss.data.item()))\n",
    "        iteration += 1\n",
    "    accuracy = correct.float() / total\n",
    "    writer.add_scalar(\"train_accuracy\", accuracy, epoch)\n",
    "    print('Accuracy of the model on the 60000 train images: % f %%' % (100*accuracy))\n",
    "    # train_acc.append(100 * accuracy)\n",
    "    # train_loss.append(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 100/ 390], Loss: 1.2609\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 390], Loss: 0.7697\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 390], Loss: 1.0843\n",
      "Accuracy of the model on the 60000 train images:  66.149994 %\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 390], Loss: 0.4959\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 390], Loss: 0.7758\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 390], Loss: 0.5624\n",
      "Accuracy of the model on the 60000 train images:  79.598000 %\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 390], Loss: 0.2508\n"
     ]
    }
   ],
   "source": [
    "for fine_tune_epoch in range(5):\n",
    "        train(fine_tune_epoch, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = test(new_model)\n",
    "print(val)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49f43478476cfa9c5fb667e34d8f90772758223488791fccb9ae376d503b7c97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('new_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
